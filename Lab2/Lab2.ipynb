{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el entorno está correctamente instalado, las líneas de código anteriores deben importar los paquetes sin ningún error.\n",
    "\n",
    "Nota: para el resto de las preguntas y soluciones de código, puede ingresar más celdas si lo considera necesario.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga y estudio de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargue los datos desde el archivo *adult_data.csv*. Para esto puede utilizar la librería *pandas* con su función *read_csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Genero un dataframe a partir del .csv.\n",
    "df = pd.read_csv('./adult_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los nombres de las columnas (atributos), e investigue la documentación para entender que significa cada uno de ellos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nameList = list(df.columns.values)\n",
    "print 'Atributos: ' + ', '.join(str(name) for name in nameList) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al investigar el significado de cada atributo, se le dió especial atención a descifrar el de los siguientes atributos (cuyo significado no resultaba obvio a simple vista):\n",
    "<ul>\n",
    "    <li>fnlwgt - Se refiere al peso (proporción de la población sensada) que tiene una entrada particular con respecto a la población utilizada en el censo, de acuerdo a quien haya realizado el mismo.</li>\n",
    "    <li>education-num - Se refiere al nivel más alto de educación obtenido por la persona, pero representado en forma numérica.</li>\n",
    "    <li>capital_gain - Ganancias registradas asociadas a inversiones.</li>\n",
    "    <li>capital_loss - Pérdidas de capital asociadas a inversiones.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: A continuación realice algunas conjeturas de cuáles pueden llegar a ser los atributos de mayor utilidad para predecir el nivel de ingresos (income) de una persona.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>**RESPUESTA:**</p>\n",
    "<p>Los atributos que a un nivel intuitivo podrían llegar a ser de mayor utilidad, son:</p>\n",
    "<ul>\n",
    "    <li><i>education </i>- Asumiendo que en general, una mejor/mayor educación genera individuos más capaces de desempeñarse en áreas de alta remuneración.</li>\n",
    "    <li><i>education-num </i>- Igual al atributo anterior.</li>\n",
    "    <li><i>marital-status </i>- Asumiendo que una persona soltera tendrá más horas disponibles para dedicarle a su área de desempeño.</li>\n",
    "    <li><i>occupation </i>- Por ejemplo se puede suponer que una persona que se dedica a la elaboración de artesanías debería tener un ingreso menor al de una persona especializada en algún área como profesional.</li>\n",
    "    <li><i>relationship </i>- Mismo razonamiento que con el atributo marital-status.</li>\n",
    "    <li><i>race </i>- Si bien ocurre menos a medida que pasa el tiempo, se puede suponer que va a haber una cierta diferencia entre los ingresos de personas de raza blanca y el resto por motivos de discriminación.</li>\n",
    "    <li><i>sex </i>- Similar al atributo anterior.</li>\n",
    "    <li><i>native-country </i>- Similar al atributo anterior.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar la columna **income** en un array **y** que será utilizada como atributo clase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = np.array(df['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminar la columna **fnlwgt** ya que no aporta a la solución del problema. También eliminar la columna **education-num** ya que duplica la información de la columna 'education'. Por último, eliminar la columna **income** ya que es la columna que contiene la clase que se pretende predecir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['fnlwgt']\n",
    "del df['education-num']\n",
    "del df['income']\n",
    "# Se imprime dataframe para verificar borrado.\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los atributos cuyos valores son categorías ('workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country'), deben de transformarse a valores numéricos para poder ser utilizados como entradas en los modelos de scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Por qué no es apropiado transformar un atributo de categoría en simples índices numéricos?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA: Porque se generaría una relación de órden y magnitud que el algoritmo de aprendizaje puede tomar y no es real...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice las clases *LabelEncoder* y *OneHotEncoder* del paquete *preprocessing* de *sklearn* para transformar los atributos de categorías en atributos numéricos. Guarde los datos de entrada en una matriz **X**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "le = LabelEncoder()\n",
    "# Inicializo matriz X.\n",
    "X = []\n",
    "df_copy = df.copy()\n",
    "for attributeName in df_copy:\n",
    "    # Si una columna no toma valores numericos.\n",
    "    if (df_copy[attributeName].dtype != \"int64\"):\n",
    "        # Se la transforma a valores numericos.\n",
    "        df_copy[attributeName] = le.fit_transform(df_copy[attributeName])\n",
    "\n",
    "# Obtengo el dataframe con valores numericos como una matriz de enteros.\n",
    "df_values = df_copy.values\n",
    "# tomo en cuenta solo los atributos que son categorías\n",
    "enc = OneHotEncoder(categorical_features=[1,2,3,4,5,6,7,11])\n",
    "X = enc.fit_transform(df_copy.values).toarray()\n",
    "#print X.shape\n",
    "# Codigo para ver donde se encuentra age ahora en los nuevos atributos.\n",
    "# df['age']\n",
    "# print 'age is between ' + str(enc.feature_indices_[0]) + ' and ' + str(enc.feature_indices_[1])\n",
    "# agebla = df['age']\n",
    "# distinctages = []\n",
    "# for i in agebla:\n",
    "#     if (not (i in distinctages)):\n",
    "#         distinctages.append(i)\n",
    "# print len(distinctages)\n",
    "# print distinctages\n",
    "# print df['age'].max()\n",
    "# print df['age'].min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Cuántos y cuáles son los nuevos atributos del dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:** Los atributos ahora van del índice 0 al 102, los nuevos (categorías) van desde el indice 0 hasta el 98, tomando un valor binario (0 o 1):\n",
    "\n",
    "    -'workclass' de 0 a 7.\n",
    "\n",
    "    -'education' de 8 a 23.\n",
    "\n",
    "    -'marital-status' de 24 a 30.\n",
    "\n",
    "    -'occupation' de 31 a 45.\n",
    "\n",
    "    -'relationship' de 46 a 51.\n",
    "\n",
    "    -'race' de 52 a 56.\n",
    "\n",
    "    -'sex' de 57 a 58.\n",
    "\n",
    "    -'native-country' de 59 a 98.\n",
    "\n",
    "Finalmente siguen los atributos que no son categorías, del índice 99 al 102:\n",
    "\n",
    "    -'age' (99), 'capital-gain' (100), 'capital-loss' (101) y 'hours-per-week' (102).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print enc.feature_indices_\n",
    "#print enc.active_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partición de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder entrenar y testear un algoritmo de aprendizaje, es necesario primero particionar los datos en dos conjuntos disjuntos de entrenamiento y testeo. Separe aleatoriamente un 25% de los datos para testeo, llame a los atributos de entrada como **X_test** y al vector de salida esperado **y_test**. El 75% restante se utilizará para el entrenamiento, nombre a la matriz con los datos de entrada como **X_train** y al vector de salida correspondiente como **y_train**.\n",
    "Para esto puede utilizar la función *train_test_split* del paquete *cross_validation* de *sklearn*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#print X_train\n",
    "#print y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine el tamaño de las matrices y vectores generados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.size\n",
    "print y_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos particionados los datos en entrenamiento y testeo, podemos comenzar a entrenar los algoritmos.\n",
    "\n",
    "Genere un modelo 'dt' entrenando un algoritmo de árboles de decisión (ver el paquete *tree* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " from sklearn import tree\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(X_train, y_train)\n",
    "\n",
    "# se prueba modelo\n",
    "#print X_test[0]\n",
    "out_dt = dt.predict(X_test)\n",
    "#print'---------------------'\n",
    "#print y_test\n",
    "diff = 0\n",
    "#for x in range(len(y_test)):\n",
    "#    if y_test[x] != out[x]:\n",
    "#        diff += 1\n",
    "#print 'Se equivocó en un ' + str(float(diff)/len(y_test) * 100) + '%.'\n",
    "print(\"Cantidad de errores sobre un total de %d : %d\" % (X_test.shape[0],(y_test != out_dt).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'nb' entrenando un algoritmo de Naive Bayes (ver el paquete *naive_bayes* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "out_nb = nb.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Cantidad de errores sobre un total de %d : %d\" % (X_test.shape[0],(y_test != out_nb).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genere un modelo 'svc' entrenando un algoritmo de Support Vector Machines (ver el paquete *svm* de *sklearn*) con el vector de entrada X_train y el vector de salida y_train. Utilice los valores por defecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "out_svc = svc.predict(X_test)\n",
    "#print(svc.predict(X_test))\n",
    "print(\"Cantidad de errores sobre un total de %d : %d\" % (X_test.shape[0],(y_test != out_svc).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de tener los modelos entrenados, podemos medir qué tan bien funcionan los modelos (su capacidad de predicción) utlizando medidas standard como accuracy, precision, recall y medida-f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: De la definición de cada una de las medidas de perfomance (accuracy, precision, recall y medida-f)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n",
    "    -accuracy:  Es la proximidad de los resultados de la medición realizada y el valor verdadero.\n",
    "    \n",
    "    -precision: Es la repetibilidad, o reproducibilidad de la medición realizada. En reconocimiento de patrones y la recuperación de información con clasificación binaria, la precisión (también llamado valor predictivo positivo) es la fracción de casos recuperados que son relevantes.\n",
    "    \n",
    "    -recall:    Es el cociente TP / (TP + FN), donde TP es el número de verdaderos positivos y FN el número de falsos negativos. Intuitivamente es la capacidad del clasificador para encontrar todas las muestras positivas. Siendo 1 el mejor valor y 0 el peor.\n",
    "    \n",
    "    -medida-f:  Se puede interpretar como un promedio ponderado entre precision y recall, alcanzando su mejor valor en 1 y su peor en 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implemente una función 'imprimir_performance' que dado un vector de entrada 'X', un vector de salida 'y', y un clasificador 'clf':\n",
    "- Realice la predicción para el vector de entrada X.\n",
    "- Imprima la medida de accuracy.\n",
    "- Imprima precision, recall y medida f de cada clase.\n",
    "- Imprima la matriz de confusión.\n",
    "\n",
    "Para esto puede utilizar el paquete *metrics* de *sklearn*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "def imprimir_performance(X, y, clf):\n",
    "    out = clf.predict(X)\n",
    "    print 'accuracy: ' + str(accuracy_score(y, out))\n",
    "    p, r, f, s = precision_recall_fscore_support(y, out)\n",
    "    print 'precision: ' + str(p)\n",
    "    print 'recall: ' + str(r)\n",
    "    print 'medida-f: ' + str(f)\n",
    "    print 'confusion matrix:' \n",
    "    print confusion_matrix(y, out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **dt** basado en árboles de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **nb** basado en Naive Bayes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilice la función **imprimir_performance** para imprimir las medidas de performance para el clasificador **svc** basado en Support Vector Machines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imprimir_performance(X_test, y_test, svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Realice un breve análisis de los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrene y mida la perfomance de los calsifificadores anteriores, pero ahora utilizando el algoritmo de validación cruzada (cross validation) tomando 5 particiones. Imprima el promedio de accuracy obtenido para cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Describa brevemente cuáles son las ventajas de utilizar validación cruzada en vez de realizar una único esquema de partición como se hizo al principio.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mejorando los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen varias técnicas que pueden ser utilizadas para mejorar los resultados de nuestros modelos. A continuación utilizaremos técnias de **selección de atributos** y de **ajuste de hiperparámetros**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestros entrenamientos hemos utilizado todos los atributos disponibles para entrenar nuestros modelos. Pero no siempre esto lleva a los mejores resultados, de hecho muchas veces, trabajar con un conjunto reducido de atributos devuelve mejores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Investigue de qué se trata la técnica de selección de atributos (feature selection) y argumente brevemente por qué puede mejorar la performance de un algoritmo de aprendizaje automático.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizando el paquete *feature_selection* de *sklearn*, seleccione e imprima la lista de los 20 mejores atributos según la medida estadística chi^2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intente obtener la lista de los mejores N atributos, donde N sea la cantidad mínima posible de atributos que mantenga o mejore las medidas de performance obtenidas con validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el conjunto de atributos obtenido, entrene los clasificadores nuevamente y verifique que las medidas de precision, recall mejoran en general:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ajuste de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo general, cada algoritmo y modelo de aprendizaje automático posee parámetros configurables. Estos parámetros se los suele denominar 'hiperparámetros' del algoritmo, ya que son parámetros que el algoritmo no ajusta automáticamente, sino que son ajustados por el \"usuario\".\n",
    "\n",
    "La correcta selección de estos hiperparámetros por lo general tiene una gran incidencia en la performance de los algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Para los modelos generados anteriormente (Árbol de decisión, Naive Bayes y Support Vector Machines), investigue en la documentación de scikit-learn cuáles son sus hiperparámetros y qué valores toman. A continuación liste y de una breve descripción de cada uno:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebe diferentes configuraciones de hiperparámetros para los modelos anteriores de modo de mejorar los resultados de performance obtenidos mediante la función *imprimir_performance*.\n",
    "\n",
    "Para esto puede realizarlo manualmente o buscar una estrategia más avanzada utilizando la clase *GridSearchCV* del paquete *grid_search* de *sklearn*. Esta clase permite definir una grilla de parámetros y posibles valores para luego entrenar el modelo con todas sus posibles combinaciones y devolver la configuración que retorna la mejor performance.\n",
    "\n",
    "En caso de tener que combinar varios procesos de extracción y selección de atributos junto con un modelo de aprendizaje, se recomienda utilizar la clase *Pipeline* del paquete *pipeline* de *sklearn*.\n",
    "\n",
    "Tener en cuenta que si la grilla es muy grande, el proceso puede requerir mucho tiempo de cómputo y memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTAS:**\n",
    "- **Cuáles son los valores de los hiperparámetros con los cuales se obtienen los mejores resultados de performance?**\n",
    "- **Con qué modelo se obtienen los mejores resultados de precision y recall?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Escriba las conclusiones generales que haya obtenido de la tarea.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección trabajaremos con clasificación de imágenes. Cada instancia a clasificar es una imagen con un dígito escrito a mano. El objetivo es detectar el dígito correspondiente a cada imagen. Para eso utilizaremos un dataset de *sklearn.datasets* que contiene imágenes de dígitos escritos a mano etiquetadas. Cada imagen se representa como un vector de pixeles.\n",
    "\n",
    "Utilizar la función *load_digits* para importar los datos de dígitos escritos a mano. Inspeccionar su contenido (data, target, images y target_names), renderizar el dígito de la primera instancia del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt \n",
    "digits = load_digits()\n",
    "plt.gray() \n",
    "plt.matshow(digits.images[0])\n",
    "print digits.target[0]\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Particionar los datos en dos conjuntos dijuntos de entrenamiento y testeo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=42)\n",
    "\n",
    "print X_train\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraer atributos de las imágenes para ser utilizados en el modelo de clasificación. Para esto, investigar las clases de Principal Component Analysis (PCA) del paquete sklearn.decomposition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=40)\n",
    "pca.fit(X_train)\n",
    "print(pca.explained_variance_ratio_) \n",
    "train=pca.transform(X_train)\n",
    "pca = PCA(n_components=40)\n",
    "pca.fit(X_test)\n",
    "test=pca.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Explique el método de extracción de atributos y justifique su elección.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elija dos algoritmos de aprendizaje y entrene e intente obtener los mejores modelos de clasificación posibles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(activation='logistic', hidden_layer_sizes=8, learning_rate_init=.01)\n",
    "mlp.fit(X_train, y_train)\n",
    "print mlp.predict(X_test[1])\n",
    "print y_test[1]\n",
    "print mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprima los mejores resultados de precision, recall y accuracy para los algoritmos seleccionados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREGUNTA: Analice los resultados obtenidos.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RESPUESTA:**"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
